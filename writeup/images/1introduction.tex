\chapter{Introduction}
\label{chapter:intro}
A wide range of cryptanalytic techniques have been developed and applied on different kinds of information systems throughout the history. This thesis work focuses on a specific type of statistical cryptanalysis of symmetric key cryptosystems. More specifically, it analyses the SSA on a certain kind of block ciphers. Among the various different kinds of known statistical cryptanalysis techniques, linear and differential cryptanalysis now have been quite familiar and even taught in university courses. In addition, different variants of these techniques namely multidimensional linear (ML), truncated differential (TD) cryptanalysis have also been invented in the past decades. Statistical model of the statistics used in these cryptanalytic techniques are available including their data and time complexities in parallel with their error probabilities. \par \noindent The statistics used in the linear and differential cryptanalysis are the \textit{correlation} of a linear approximation  and the \textit{differential probability} of a plaintext-ciphertext differential, respectively \cite{Celine_Kaisa_Links_2013}. Over the past few decades, different researchers have published links among the statistics of different cryptanalytic techniques. Chabaud and Vaudenay have shown that, differential probabilities and squared correlations are linked to each other by Walsh transform \cite{Chabaud_Vaudenay_link}. Blondeau and Nyberg have shown various links between TD and ML \cite{Celine_Kaisa_Links_2013,Celine_Kaisa_Links_2014}. Although statistical saturation (SS) is a relatively new kind of statistical cryptanalytic technique proposed by Collard and Standaert \cite{SSA_Collard_Standaert}, few attempts have already been made by researchers to link SSA with other statistical cryptanalytic techniques so that the already known statistical models can be used to apply SSA. Blondeau and Nyberg have shown links in between TD and SS \cite{Celine_Kaisa_Links_2014} attacks and have given a model for the SSA based on the existing model of the TD attack. Leander have shown that there is a mathematical link between SSA and ML cryptanalysis \cite{Leander_link}. However, any concrete statistical model of SSA is yet to be developed. In this work, instead of using any link with other statistical cryptanalytic techniques, we look at SSA directly and develop a statistical model.\par \noindent As explained in \cite{SSA_Collard_Standaert}, in SSA, the plaintext space is  partitioned into two parts. One part is fixed to a chosen value while the other part iterates over all the possible values. The ciphertext space is also partitioned into two parts. As the variable part of the plaintext space iterates over different values, the distribution of one part of the ciphertext space is observed. If the plaintext and ciphertext spaces are partitioned considering relevant weakness of the block cipher then it is possible to gain some insight of the cipher. Because of this non-uniform distribution of these chosen plaintexts, after a sufficient number of encryption of them, the one part of the corresponding ciphertexts also shows non-uniform distribution. The technique to find such a weakness is a different problem and out of scope of this thesis. Nevertheless, we have discussed the basic principles of finding such a weakness in the Chapter \ref{chapter:block_cipher_cryptanalysis}. However, we mostly focus on how to exploit such a non-uniformity extracted from the found weakness. In the original paper of Collard and Staendart \cite{SSA_Collard_Standaert}, they have suggested two approaches to exploit this non-uniformity to reveal the secret key partially. In the first approach the attacker calculates all the ciphertext distributions for all possible keys and stores them in a table. That is, the table stores separate distributions for each key. Then it finds the distribution from this table that minimizes the distance with the distribution computed from a secret key. The corresponding key of that distribution in the table is then assumed to be the secret key. Computing this table is costly and the second approach solves the problem by introducing a distinguishing attack using last round trick. If the cipher has $r$ rounds, then the ciphertexts are partially decrypted through the last round only by all the parital keys. The key that produces ciphertext distribution which has maximum distance from uniform distribution is assumed to be a part of the correct key. Indeed, otherwise any wrong key will make the ciphertext distribution to be more uniform. We look at this distingushing attack and find a statistic that can be used to distinguish the ciphertext distribution from random. And then we also find the model that shows the data complexity, that is, the number of required plaintext-ciphertext pairs so that the computed statistic can reach to a value that is able to distinguish the distribution from random with a significantly low error probability.\par \noindent The statistic used to analyze this distribution is $\chi^2$ distributed which is denoted in this thesis by $T$. Given a $T$ computed from a sample, we apply a statistical test to identify if $T$ is random or it follows some other known distribution of a known block cipher. The distribution of the statistic $T$ for a cipher is then theoretically approximated considering different kinds of fixations in the plaintext space. It is approximated for any arbitrarily fixed fixation, for variable fixation, for arbitrarily fixed set of fixations, and for variable set of fixations.\par \noindent In Chapter \ref{chapter:block_cipher_cryptanalysis}, the block cipher and SSA is formally defined. We have discussed the definition and properties of different kind of statistical distributions in Chapter \ref{chapter:statistics}. The concept of statistical tests that can distinguish an observed distribution in between two given distributions is also discussed in this chapter. In Chapter \ref{chapter:statistical_distinguishers} we present the derivations of different $T$ in detail. In Chapter $\ref{chapter:data_complexity_of_SSA}$, we have derived the data complexity of SSA. Chapter $\ref{chapter:experiment}$ has been dedicated to the experiments that show the validity of the models. Finally in Chapter \ref{chapter:conclusions}, we conclude the thesis.